{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TensorFlow 2.0 - Customization - Better performance with tf.function.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sourcecode369/TensorFlow-2.0/blob/master/tensorflow_2.0_docs/TensorFlow%20Core/Tutorials/Customization/tf.function/TensorFlo0w_2_0_Customization_Better_performance_with_tf_function.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gD5u-ugwrbfc",
        "colab_type": "text"
      },
      "source": [
        "### Installing TensorFlow"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cx7kYWM5oNDb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 666
        },
        "outputId": "1455e0c7-600c-4a17-b767-20cafdc7c172"
      },
      "source": [
        "!pip install --upgrade tensorflow-gpu"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow-gpu\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/25/44/47f0722aea081697143fbcf5d2aa60d1aee4aaacb5869aee2b568974777b/tensorflow_gpu-2.0.0-cp36-cp36m-manylinux2010_x86_64.whl (380.8MB)\n",
            "\u001b[K     |████████████████████████████████| 380.8MB 77kB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.12.0)\n",
            "Requirement already satisfied, skipping upgrade: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.1.0)\n",
            "Requirement already satisfied, skipping upgrade: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.15.0)\n",
            "Requirement already satisfied, skipping upgrade: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (0.8.1)\n",
            "Requirement already satisfied, skipping upgrade: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.1.0)\n",
            "Collecting tensorflow-estimator<2.1.0,>=2.0.0 (from tensorflow-gpu)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/fc/08/8b927337b7019c374719145d1dceba21a8bb909b93b1ad6f8fb7d22c1ca1/tensorflow_estimator-2.0.1-py2.py3-none-any.whl (449kB)\n",
            "\u001b[K     |████████████████████████████████| 450kB 43.1MB/s \n",
            "\u001b[?25hCollecting tensorboard<2.1.0,>=2.0.0 (from tensorflow-gpu)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9b/a6/e8ffa4e2ddb216449d34cfcb825ebb38206bee5c4553d69e7bc8bc2c5d64/tensorboard-2.0.0-py3-none-any.whl (3.8MB)\n",
            "\u001b[K     |████████████████████████████████| 3.8MB 31.5MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.0.8)\n",
            "Requirement already satisfied, skipping upgrade: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.11.2)\n",
            "Requirement already satisfied, skipping upgrade: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (0.1.7)\n",
            "Requirement already satisfied, skipping upgrade: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (3.10.0)\n",
            "Requirement already satisfied, skipping upgrade: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (0.33.6)\n",
            "Requirement already satisfied, skipping upgrade: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (3.1.0)\n",
            "Requirement already satisfied, skipping upgrade: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.16.5)\n",
            "Requirement already satisfied, skipping upgrade: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (0.8.0)\n",
            "Requirement already satisfied, skipping upgrade: gast==0.2.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (0.2.2)\n",
            "Requirement already satisfied, skipping upgrade: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow-gpu) (3.1.1)\n",
            "Requirement already satisfied, skipping upgrade: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow-gpu) (0.16.0)\n",
            "Requirement already satisfied, skipping upgrade: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow-gpu) (41.4.0)\n",
            "Requirement already satisfied, skipping upgrade: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.8->tensorflow-gpu) (2.8.0)\n",
            "\u001b[31mERROR: tensorflow 1.15.0 has requirement tensorboard<1.16.0,>=1.15.0, but you'll have tensorboard 2.0.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: tensorflow 1.15.0 has requirement tensorflow-estimator==1.15.1, but you'll have tensorflow-estimator 2.0.1 which is incompatible.\u001b[0m\n",
            "Installing collected packages: tensorflow-estimator, tensorboard, tensorflow-gpu\n",
            "  Found existing installation: tensorflow-estimator 1.15.1\n",
            "    Uninstalling tensorflow-estimator-1.15.1:\n",
            "      Successfully uninstalled tensorflow-estimator-1.15.1\n",
            "  Found existing installation: tensorboard 1.15.0\n",
            "    Uninstalling tensorboard-1.15.0:\n",
            "      Successfully uninstalled tensorboard-1.15.0\n",
            "Successfully installed tensorboard-2.0.0 tensorflow-estimator-2.0.1 tensorflow-gpu-2.0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-d4gud-BreWZ",
        "colab_type": "text"
      },
      "source": [
        "### Importing the dependencies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b9f_4b1In76k",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "7335c912-1ffd-4198-8f20-d4cd608a0aae"
      },
      "source": [
        "%%time \n",
        "from __future__ import absolute_import, print_function, division, unicode_literals\n",
        "\n",
        "%load_ext tensorboard\n",
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "%config InlineBackend.figure_format = \"retina\"\n",
        "%matplotlib inline\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "print(tf.__version__)\n",
        "\n",
        "import warnings; warnings.simplefilter(\"ignore\")"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.0.0\n",
            "CPU times: user 1.25 s, sys: 153 ms, total: 1.4 s\n",
            "Wall time: 1.41 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Saoq6_WErjsx",
        "colab_type": "text"
      },
      "source": [
        "### Setting up TensorFlow"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FGSesDx4o4Bc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "dc6b27d4-f020-48cf-f4ea-6042556f9bb2"
      },
      "source": [
        "tf.debugging.set_log_device_placement(True)\n",
        "tf.config.set_soft_device_placement(True)\n",
        "print(f\"Executing eagerly: {tf.executing_eagerly()}\")\n",
        "print(f\"Intializing random seed {tf.random.set_seed(1)}\")\n",
        "try:\n",
        "    %tensorflow_version 2.x\n",
        "except:\n",
        "    print(\"Tensorflow version 2 not loaded.\")"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Executing eagerly: True\n",
            "Intializing random seed None\n",
            "TensorFlow is already loaded. Please restart the runtime to change versions.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j5UNU0jPrsbD",
        "colab_type": "text"
      },
      "source": [
        "### Helper code to demostrate different kinds of errors"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OL3TrRGopWiC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import contextlib\n",
        "\n",
        "@contextlib.contextmanager\n",
        "def assert_raises(error_class):\n",
        "  try:\n",
        "    yield\n",
        "  except error_class as e:\n",
        "    print('Caught expected exception \\n  {}: {}'.format(error_class, e))\n",
        "  except Exception as e:\n",
        "    print('Got unexpected exception \\n  {}: {}'.format(type(e), e))\n",
        "  else:\n",
        "    raise Exception('Expected {} to be raised but no error was raised!'.format(\n",
        "        error_class))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ecJh-ygIqSdr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "fc52cb05-06ba-40f1-c2a0-57d5bd486841"
      },
      "source": [
        "# a function is like an op\n",
        "@tf.function\n",
        "def add(a,b):\n",
        "    return a+b\n",
        "\n",
        "add(tf.ones([2,2]), tf.ones([2,2]))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Executing op Fill in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op __inference_add_13 in device /job:localhost/replica:0/task:0/device:GPU:0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: id=14, shape=(2, 2), dtype=float32, numpy=\n",
              "array([[2., 2.],\n",
              "       [2., 2.]], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eRhyBz64qfye",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "1750f38d-b272-4e90-f0fc-82dc566edc95"
      },
      "source": [
        "# Functions have gradients\n",
        "@tf.function\n",
        "def add(a,b):\n",
        "    return a+b\n",
        "\n",
        "v = tf.Variable(1.0)\n",
        "with tf.GradientTape() as tape:\n",
        "    result = add(v, 1.0)\n",
        "tape.gradient(result, v)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op VarIsInitializedOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op LogicalNot in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op Assert in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op AssignVariableOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op __forward_add_34 in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op __inference___backward_add_30_35 in device /job:localhost/replica:0/task:0/device:GPU:0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: id=38, shape=(), dtype=float32, numpy=1.0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jIGUxEoBq4oU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "68e7d93a-0014-4708-ce34-0bbf0ecfc36a"
      },
      "source": [
        "# can use functions inside functions\n",
        "@tf.function \n",
        "def dense_layer(x,w,b):\n",
        "    return add(tf.matmul(x,w),b)\n",
        "\n",
        "dense_layer(tf.ones([3,2]), tf.ones([2,2]), tf.ones([2]))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Executing op __inference_dense_layer_63 in device /job:localhost/replica:0/task:0/device:GPU:0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: id=64, shape=(3, 2), dtype=float32, numpy=\n",
              "array([[3., 3.],\n",
              "       [3., 3.],\n",
              "       [3., 3.]], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "79dTCosOrYlv",
        "colab_type": "text"
      },
      "source": [
        "### Tracing and polymorphism"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ORq1q_UIr1h7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "701d4dfa-e507-469f-acc3-ea3a29f6efff"
      },
      "source": [
        "# functions are polymorphic\n",
        "@tf.function\n",
        "def double(a):\n",
        "    print(\"Tracing with\",a)\n",
        "    return a+a\n",
        "\n",
        "print(double(tf.constant(1)))\n",
        "print()\n",
        "print(double(tf.constant(1.1)))\n",
        "print()\n",
        "print(double(tf.constant(\"AI\")))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tracing with Tensor(\"a:0\", shape=(), dtype=int32)\n",
            "Executing op __inference_double_71 in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "tf.Tensor(2, shape=(), dtype=int32)\n",
            "\n",
            "Tracing with Tensor(\"a:0\", shape=(), dtype=float32)\n",
            "Executing op __inference_double_78 in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "tf.Tensor(2.2, shape=(), dtype=float32)\n",
            "\n",
            "Tracing with Tensor(\"a:0\", shape=(), dtype=string)\n",
            "Executing op __inference_double_85 in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "tf.Tensor(b'AIAI', shape=(), dtype=string)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GU1Eo_nMsezC",
        "colab_type": "text"
      },
      "source": [
        "> To control the tracing behaviour, use the following techniques:\n",
        "    \n",
        "    * Create a new tf.function. Separate tf.function objects are guarenteed not to share traces.\n",
        "\n",
        "    * Use `get_concrete_function` method to get a specific trace\n",
        "\n",
        "    * Specify `input_signature` when calling tf.function to trace only once per calling graph."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TW7n7W4WtCAx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        },
        "outputId": "4948b2ea-bc89-48ff-af16-ab9c96ccbc6e"
      },
      "source": [
        "print(\"obtating concrete traces\")\n",
        "double_strings = double.get_concrete_function(tf.TensorSpec(shape=None,dtype=tf.string))\n",
        "print(\"Executing traced function\")\n",
        "print(double_strings(tf.constant(\"a\")))\n",
        "print(double_strings(a=tf.constant(\"b\")))\n",
        "print(\"Using a concrete trace with incompatible types will throw an error\")\n",
        "with assert_raises(tf.errors.InvalidArgumentError):\n",
        "    double_strings(tf.constant(1.))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "obtating concrete traces\n",
            "Executing traced function\n",
            "tf.Tensor(b'aa', shape=(), dtype=string)\n",
            "tf.Tensor(b'bb', shape=(), dtype=string)\n",
            "Using a concrete trace with incompatible types will throw an error\n",
            "Caught expected exception \n",
            "  <class 'tensorflow.python.framework.errors_impl.InvalidArgumentError'>: cannot compute __inference_double_91 as input #0(zero-based) was expected to be a string tensor but is a float tensor [Op:__inference_double_91]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VqtLCgzit-B2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "1f77b0f4-c17c-489f-ffc2-5200a045b9fc"
      },
      "source": [
        "@tf.function(input_signature=(tf.TensorSpec(shape=[None], dtype=tf.int32),))\n",
        "def next_collatz(x):\n",
        "  print(\"Tracing with\", x)\n",
        "  return tf.where(x % 2 == 0, x // 2, 3 * x + 1)\n",
        "print(next_collatz(tf.constant([1, 2])))\n",
        "with assert_raises(ValueError):\n",
        "  next_collatz(tf.constant([[1, 2], [3, 4]]))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tracing with Tensor(\"x:0\", shape=(None,), dtype=int32)\n",
            "Executing op __inference_next_collatz_136 in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "tf.Tensor([4 1], shape=(2,), dtype=int32)\n",
            "Caught expected exception \n",
            "  <class 'ValueError'>: Python inputs incompatible with input_signature:\n",
            "  inputs: (\n",
            "    tf.Tensor(\n",
            "[[1 2]\n",
            " [3 4]], shape=(2, 2), dtype=int32))\n",
            "  input_signature: (\n",
            "    TensorSpec(shape=(None,), dtype=tf.int32, name=None))\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uxvqtXt50Ls7",
        "colab_type": "text"
      },
      "source": [
        "#### When to retrace?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vW1SBnRe0oZ3",
        "colab_type": "text"
      },
      "source": [
        "A polymorphic tf.function keeps a cache of concrete functions generated by tracing. The cache keys are effectively tuples of keys generated from the function args and kwargs. The key generated for a tf.Tensor argument is its shape and type. The key generated for a Python primitive is its value. For all other Python types, the keys are based on the object id() so that methods are traced independently for each instance of a class. In the future, TensorFlow may add more sophisticated caching for Python objects that can be safely converted to tensors."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pP7ARMLk0rYe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}