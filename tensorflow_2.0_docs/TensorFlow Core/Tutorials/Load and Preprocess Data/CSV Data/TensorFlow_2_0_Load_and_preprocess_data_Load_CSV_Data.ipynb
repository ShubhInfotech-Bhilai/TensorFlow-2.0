{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TensorFlow 2.0 - Load and preprocess data - Load CSV Data.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sourcecode369/TensorFlow-2.0/blob/master/tensorflow_2.0_docs/TensorFlow%20Core/Tutorials/Load%20and%20Preprocess%20Data/CSV%20Data/TensorFlow_2_0_Load_and_preprocess_data_Load_CSV_Data.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cza8gOKmIlkc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "8140eae9-b186-4be2-f126-980e0087b64b"
      },
      "source": [
        "!pip install --upgrade tensorflow-gpu"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow-gpu\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/25/44/47f0722aea081697143fbcf5d2aa60d1aee4aaacb5869aee2b568974777b/tensorflow_gpu-2.0.0-cp36-cp36m-manylinux2010_x86_64.whl (380.8MB)\n",
            "\u001b[K     |████████████████████████████████| 380.8MB 43kB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.17.3)\n",
            "Requirement already satisfied, skipping upgrade: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.1.0)\n",
            "Requirement already satisfied, skipping upgrade: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.1.0)\n",
            "Requirement already satisfied, skipping upgrade: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.12.0)\n",
            "Requirement already satisfied, skipping upgrade: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (3.10.0)\n",
            "Requirement already satisfied, skipping upgrade: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (0.8.1)\n",
            "Requirement already satisfied, skipping upgrade: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (0.1.7)\n",
            "Requirement already satisfied, skipping upgrade: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.0.8)\n",
            "Requirement already satisfied, skipping upgrade: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (3.1.0)\n",
            "Collecting tensorboard<2.1.0,>=2.0.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d3/9e/a48cd34dd7b672ffc227b566f7d16d63c62c58b542d54efa45848c395dd4/tensorboard-2.0.1-py3-none-any.whl (3.8MB)\n",
            "\u001b[K     |████████████████████████████████| 3.8MB 34.5MB/s \n",
            "\u001b[?25hCollecting tensorflow-estimator<2.1.0,>=2.0.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/fc/08/8b927337b7019c374719145d1dceba21a8bb909b93b1ad6f8fb7d22c1ca1/tensorflow_estimator-2.0.1-py2.py3-none-any.whl (449kB)\n",
            "\u001b[K     |████████████████████████████████| 450kB 52.8MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.15.0)\n",
            "Requirement already satisfied, skipping upgrade: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (0.33.6)\n",
            "Requirement already satisfied, skipping upgrade: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (0.8.0)\n",
            "Requirement already satisfied, skipping upgrade: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.11.2)\n",
            "Requirement already satisfied, skipping upgrade: gast==0.2.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (0.2.2)\n",
            "Requirement already satisfied, skipping upgrade: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow-gpu) (41.4.0)\n",
            "Requirement already satisfied, skipping upgrade: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.8->tensorflow-gpu) (2.8.0)\n",
            "Requirement already satisfied, skipping upgrade: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow-gpu) (0.16.0)\n",
            "Requirement already satisfied, skipping upgrade: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow-gpu) (0.4.1)\n",
            "Collecting google-auth<2,>=1.6.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c5/9b/ed0516cc1f7609fb0217e3057ff4f0f9f3e3ce79a369c6af4a6c5ca25664/google_auth-1.6.3-py2.py3-none-any.whl (73kB)\n",
            "\u001b[K     |████████████████████████████████| 81kB 10.9MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow-gpu) (3.1.1)\n",
            "Requirement already satisfied, skipping upgrade: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.1.0,>=2.0.0->tensorflow-gpu) (1.2.0)\n",
            "Requirement already satisfied, skipping upgrade: cachetools>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow-gpu) (3.1.1)\n",
            "Requirement already satisfied, skipping upgrade: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow-gpu) (0.2.7)\n",
            "Requirement already satisfied, skipping upgrade: rsa>=3.1.4 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow-gpu) (4.0)\n",
            "Requirement already satisfied, skipping upgrade: requests>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.1.0,>=2.0.0->tensorflow-gpu) (2.21.0)\n",
            "Requirement already satisfied, skipping upgrade: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.1.0,>=2.0.0->tensorflow-gpu) (3.1.0)\n",
            "Requirement already satisfied, skipping upgrade: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.6/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow-gpu) (0.4.7)\n",
            "Requirement already satisfied, skipping upgrade: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0.0->requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.1.0,>=2.0.0->tensorflow-gpu) (3.0.4)\n",
            "Requirement already satisfied, skipping upgrade: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0.0->requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.1.0,>=2.0.0->tensorflow-gpu) (1.24.3)\n",
            "Requirement already satisfied, skipping upgrade: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0.0->requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.1.0,>=2.0.0->tensorflow-gpu) (2.8)\n",
            "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0.0->requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.1.0,>=2.0.0->tensorflow-gpu) (2019.9.11)\n",
            "\u001b[31mERROR: tensorflow 1.15.0 has requirement tensorboard<1.16.0,>=1.15.0, but you'll have tensorboard 2.0.1 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: tensorflow 1.15.0 has requirement tensorflow-estimator==1.15.1, but you'll have tensorflow-estimator 2.0.1 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: tensorboard 2.0.1 has requirement grpcio>=1.24.3, but you'll have grpcio 1.15.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: google-colab 1.0.0 has requirement google-auth~=1.4.0, but you'll have google-auth 1.6.3 which is incompatible.\u001b[0m\n",
            "Installing collected packages: google-auth, tensorboard, tensorflow-estimator, tensorflow-gpu\n",
            "  Found existing installation: google-auth 1.4.2\n",
            "    Uninstalling google-auth-1.4.2:\n",
            "      Successfully uninstalled google-auth-1.4.2\n",
            "  Found existing installation: tensorboard 1.15.0\n",
            "    Uninstalling tensorboard-1.15.0:\n",
            "      Successfully uninstalled tensorboard-1.15.0\n",
            "  Found existing installation: tensorflow-estimator 1.15.1\n",
            "    Uninstalling tensorflow-estimator-1.15.1:\n",
            "      Successfully uninstalled tensorflow-estimator-1.15.1\n",
            "Successfully installed google-auth-1.6.3 tensorboard-2.0.1 tensorflow-estimator-2.0.1 tensorflow-gpu-2.0.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "google"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aS2OEV_ZI6YK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import absolute_import, print_function, division, unicode_literals\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_EGFoZ_wJNMv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "8f393fb5-c7f5-4a8c-8a88-94068bf4f715"
      },
      "source": [
        "TRAIN_DATA_URL = \"https://storage.googleapis.com/tf-datasets/titanic/train.csv\"\n",
        "TEST_DATA_URL = \"https://storage.googleapis.com/tf-datasets/titanic/eval.csv\"\n",
        "\n",
        "train_file_path = tf.keras.utils.get_file(\"train.csv\",TRAIN_DATA_URL)\n",
        "test_file_path = tf.keras.utils.get_file('test.csv',TEST_DATA_URL)\n",
        "\n",
        "np.set_printoptions(precision=3)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tf-datasets/titanic/train.csv\n",
            "32768/30874 [===============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tf-datasets/titanic/eval.csv\n",
            "16384/13049 [=====================================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "97HqvT98JnmU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "337a3d20-ce07-488f-95df-5f2d205d36dc"
      },
      "source": [
        "!head {train_file_path}"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "survived,sex,age,n_siblings_spouses,parch,fare,class,deck,embark_town,alone\n",
            "0,male,22.0,1,0,7.25,Third,unknown,Southampton,n\n",
            "1,female,38.0,1,0,71.2833,First,C,Cherbourg,n\n",
            "1,female,26.0,0,0,7.925,Third,unknown,Southampton,y\n",
            "1,female,35.0,1,0,53.1,First,C,Southampton,n\n",
            "0,male,28.0,0,0,8.4583,Third,unknown,Queenstown,y\n",
            "0,male,2.0,3,1,21.075,Third,unknown,Southampton,n\n",
            "1,female,27.0,0,2,11.1333,Third,unknown,Southampton,n\n",
            "1,female,14.0,1,0,30.0708,Second,unknown,Cherbourg,n\n",
            "1,female,4.0,1,1,16.7,Third,G,Southampton,n\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kOaJQLUlJreS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "LABEL_COLUMN = 'survived'\n",
        "LABELS = [0, 1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5rR31yAoJ6lM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "outputId": "a609e174-5fe1-4f05-86e9-499d3826a50d"
      },
      "source": [
        "def get_dataset(filepath, **kwargs):\n",
        "  dataset = tf.data.experimental.make_csv_dataset(\n",
        "      filepath,\n",
        "      batch_size=5,\n",
        "      label_name=LABEL_COLUMN,\n",
        "      na_value=\"?\",\n",
        "      num_epochs=1,\n",
        "      ignore_errors=True,\n",
        "      **kwargs\n",
        "  )\n",
        "  return dataset\n",
        "\n",
        "raw_train_data = get_dataset(train_file_path)\n",
        "raw_test_data = get_dataset(test_file_path)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/data/experimental/ops/readers.py:521: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oXeF7GMYKhOE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "outputId": "feb939ab-1fed-4574-b87c-419c1bf0aae4"
      },
      "source": [
        "raw_train_data.element_spec"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(OrderedDict([('sex', TensorSpec(shape=(None,), dtype=tf.string, name=None)),\n",
              "              ('age', TensorSpec(shape=(None,), dtype=tf.float32, name=None)),\n",
              "              ('n_siblings_spouses',\n",
              "               TensorSpec(shape=(None,), dtype=tf.int32, name=None)),\n",
              "              ('parch', TensorSpec(shape=(None,), dtype=tf.int32, name=None)),\n",
              "              ('fare', TensorSpec(shape=(None,), dtype=tf.float32, name=None)),\n",
              "              ('class', TensorSpec(shape=(None,), dtype=tf.string, name=None)),\n",
              "              ('deck', TensorSpec(shape=(None,), dtype=tf.string, name=None)),\n",
              "              ('embark_town',\n",
              "               TensorSpec(shape=(None,), dtype=tf.string, name=None)),\n",
              "              ('alone',\n",
              "               TensorSpec(shape=(None,), dtype=tf.string, name=None))]),\n",
              " TensorSpec(shape=(None,), dtype=tf.int32, name=None))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BIp-f4ByKw02",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "outputId": "a435c902-1730-444d-e3eb-c9e38fe67789"
      },
      "source": [
        "raw_test_data.element_spec"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(OrderedDict([('sex', TensorSpec(shape=(None,), dtype=tf.string, name=None)),\n",
              "              ('age', TensorSpec(shape=(None,), dtype=tf.float32, name=None)),\n",
              "              ('n_siblings_spouses',\n",
              "               TensorSpec(shape=(None,), dtype=tf.int32, name=None)),\n",
              "              ('parch', TensorSpec(shape=(None,), dtype=tf.int32, name=None)),\n",
              "              ('fare', TensorSpec(shape=(None,), dtype=tf.float32, name=None)),\n",
              "              ('class', TensorSpec(shape=(None,), dtype=tf.string, name=None)),\n",
              "              ('deck', TensorSpec(shape=(None,), dtype=tf.string, name=None)),\n",
              "              ('embark_town',\n",
              "               TensorSpec(shape=(None,), dtype=tf.string, name=None)),\n",
              "              ('alone',\n",
              "               TensorSpec(shape=(None,), dtype=tf.string, name=None))]),\n",
              " TensorSpec(shape=(None,), dtype=tf.int32, name=None))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z4nQK2EOKy4z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "211cb7eb-9f6d-40fe-fe8e-d1988064dac6"
      },
      "source": [
        "def show_batch(dataset):\n",
        "  for batch, label in dataset.take(1):\n",
        "    for key, value in batch.items():\n",
        "      print(\"{:20s}: {}\".format(key, value.numpy()))\n",
        "\n",
        "show_batch(raw_train_data)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "sex                 : [b'female' b'male' b'male' b'female' b'male']\n",
            "age                 : [ 4. 28. 31. 28. 28.]\n",
            "n_siblings_spouses  : [0 0 1 8 0]\n",
            "parch               : [1 0 1 2 0]\n",
            "fare                : [13.417  8.05  37.004 69.55   7.854]\n",
            "class               : [b'Third' b'Third' b'Second' b'Third' b'Third']\n",
            "deck                : [b'unknown' b'unknown' b'unknown' b'unknown' b'unknown']\n",
            "embark_town         : [b'Cherbourg' b'Southampton' b'Cherbourg' b'Southampton' b'Southampton']\n",
            "alone               : [b'n' b'y' b'n' b'n' b'y']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5wcZjivILEWl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "83fe6c18-51a9-408e-a6d5-3f1c79650d13"
      },
      "source": [
        "CSV_COLUMNS = ['survived', 'sex', 'age', 'n_siblings_spouses', 'parch', 'fare', 'class', 'deck', 'embark_town', 'alone']\n",
        "temp_dataset = get_dataset(train_file_path, column_names=CSV_COLUMNS)\n",
        "show_batch(temp_dataset)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "sex                 : [b'male' b'male' b'female' b'male' b'male']\n",
            "age                 : [36. 33. 19. 32. 23.]\n",
            "n_siblings_spouses  : [0 0 0 0 0]\n",
            "parch               : [0 0 0 0 0]\n",
            "fare                : [40.125  9.5   26.     8.05   7.896]\n",
            "class               : [b'First' b'Third' b'Second' b'Third' b'Third']\n",
            "deck                : [b'A' b'unknown' b'unknown' b'E' b'unknown']\n",
            "embark_town         : [b'Cherbourg' b'Southampton' b'Southampton' b'Southampton' b'Southampton']\n",
            "alone               : [b'y' b'y' b'y' b'y' b'y']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U-qn3YEjLo8p",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "019a568d-caca-4c44-f490-f1e3fcb23370"
      },
      "source": [
        "SELECT_COLUMNS = ['survived', 'age', 'n_siblings_spouses', 'class', 'deck', 'alone']\n",
        "temp_dataset = get_dataset(train_file_path, select_columns=SELECT_COLUMNS)\n",
        "show_batch(temp_dataset)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "age                 : [32. 28. 28. 50. 22.]\n",
            "n_siblings_spouses  : [0 0 0 0 0]\n",
            "class               : [b'Third' b'First' b'Third' b'Second' b'First']\n",
            "deck                : [b'E' b'C' b'unknown' b'unknown' b'B']\n",
            "alone               : [b'y' b'y' b'y' b'y' b'n']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kpO44Bl3LvmC",
        "colab_type": "text"
      },
      "source": [
        "### Data Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aj8nps7xVJO7",
        "colab_type": "text"
      },
      "source": [
        "#### Numeric Columns"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fdmQRzJfPrRv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "d068c656-f4e8-4624-d930-f8a7754e6889"
      },
      "source": [
        "SELECT_COLUMNS = ['survived', 'age', 'n_siblings_spouses', 'parch', 'fare']\n",
        "DEFAULTS = [0, 0.0, 0.0, 0.0, 0.0]\n",
        "temp_dataset = get_dataset(train_file_path, \n",
        "                           select_columns=SELECT_COLUMNS,\n",
        "                           column_defaults = DEFAULTS)\n",
        "show_batch(temp_dataset)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "age                 : [19. 28. 28. 28. 16.]\n",
            "n_siblings_spouses  : [0. 0. 0. 0. 4.]\n",
            "parch               : [0. 0. 0. 0. 1.]\n",
            "fare                : [ 8.05  14.5    7.75   7.896 39.688]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fxzdOoWnQIbo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "example_batch, labels_batch = next(iter(temp_dataset))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DwsBYlptQRth",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def pack(features, label):\n",
        "  return tf.stack(list(features.values()), axis=1), label"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nwsU2CL1QbM9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "41a7ff4c-26b2-41d9-fdbc-937109ba9074"
      },
      "source": [
        "packed_dataset = temp_dataset.map(pack, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
        "\n",
        "for features, label in packed_dataset.take(1):\n",
        "  print(features.numpy())\n",
        "  print()\n",
        "  print(label.numpy())"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 28.      0.      0.      7.05 ]\n",
            " [ 28.      1.      2.     23.45 ]\n",
            " [ 22.      0.      0.    151.55 ]\n",
            " [ 17.      0.      0.      8.663]\n",
            " [ 48.      1.      0.     39.6  ]]\n",
            "\n",
            "[0 0 1 0 1]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VqF2jEfBQvGI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "e71b3aa7-40f7-4e9c-e573-5c1ac8f7504f"
      },
      "source": [
        "show_batch(raw_train_data)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "sex                 : [b'male' b'female' b'male' b'male' b'female']\n",
            "age                 : [40. 14. 28. 31. 17.]\n",
            "n_siblings_spouses  : [0 1 3 0 1]\n",
            "parch               : [0 0 1 0 0]\n",
            "fare                : [  7.896  30.071  25.467  13.    108.9  ]\n",
            "class               : [b'Third' b'Second' b'Third' b'Second' b'First']\n",
            "deck                : [b'unknown' b'unknown' b'unknown' b'unknown' b'C']\n",
            "embark_town         : [b'Southampton' b'Cherbourg' b'Southampton' b'Southampton' b'Cherbourg']\n",
            "alone               : [b'y' b'n' b'n' b'y' b'n']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YGXUrn29Q9uu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "example_batch, labels_batch = next(iter(temp_dataset))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qTjKbsFyRFsa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class PackNumericFeature(object):\n",
        "  def __init__(self, names):\n",
        "    self.names = names\n",
        "\n",
        "  def __call__(self, features, labels):\n",
        "    numeric_features = [features.pop(name) for name in self.names]\n",
        "    numeric_features = [tf.cast(feat, tf.float32) for feat in numeric_features]\n",
        "    numeric_features = tf.stack(numeric_features, axis=-1)\n",
        "    features['numeric'] = numeric_features\n",
        "    return features, labels"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cab7a4SRR7M_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "NUMERIC_FEATURES = ['age','n_siblings_spouses','parch', 'fare']\n",
        "packed_train_data = raw_train_data.map(PackNumericFeature(NUMERIC_FEATURES), num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
        "packed_test_data = raw_test_data.map(PackNumericFeature(NUMERIC_FEATURES), num_parallel_calls=tf.data.experimental.AUTOTUNE)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pGOYlg8ASOE9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "f1bf1742-bb6d-4165-8599-ab9dcf7919c3"
      },
      "source": [
        "show_batch(packed_train_data)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "sex                 : [b'male' b'female' b'female' b'male' b'male']\n",
            "class               : [b'Third' b'Third' b'Second' b'First' b'Second']\n",
            "deck                : [b'F' b'unknown' b'unknown' b'unknown' b'unknown']\n",
            "embark_town         : [b'Southampton' b'Southampton' b'Southampton' b'Cherbourg' b'Southampton']\n",
            "alone               : [b'y' b'y' b'n' b'y' b'n']\n",
            "numeric             : [[19.     0.     0.     7.65 ]\n",
            " [ 5.     0.     0.    12.475]\n",
            " [26.     1.     1.    26.   ]\n",
            " [28.     0.     0.    30.696]\n",
            " [29.     1.     0.    21.   ]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fj1cnkXXSaPt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "example_batch, label_batch = next(iter(packed_train_data))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fOOrQKYSSl7d",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "outputId": "f013cda7-92bc-4d11-aaf7-7e04abd79bf3"
      },
      "source": [
        "desc = pd.read_csv(train_file_path)[NUMERIC_FEATURES].describe()\n",
        "desc"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>n_siblings_spouses</th>\n",
              "      <th>parch</th>\n",
              "      <th>fare</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>627.000000</td>\n",
              "      <td>627.000000</td>\n",
              "      <td>627.000000</td>\n",
              "      <td>627.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>29.631308</td>\n",
              "      <td>0.545455</td>\n",
              "      <td>0.379585</td>\n",
              "      <td>34.385399</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>12.511818</td>\n",
              "      <td>1.151090</td>\n",
              "      <td>0.792999</td>\n",
              "      <td>54.597730</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.750000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>23.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>7.895800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>28.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>15.045800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>35.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>31.387500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>80.000000</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>512.329200</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "              age  n_siblings_spouses       parch        fare\n",
              "count  627.000000          627.000000  627.000000  627.000000\n",
              "mean    29.631308            0.545455    0.379585   34.385399\n",
              "std     12.511818            1.151090    0.792999   54.597730\n",
              "min      0.750000            0.000000    0.000000    0.000000\n",
              "25%     23.000000            0.000000    0.000000    7.895800\n",
              "50%     28.000000            0.000000    0.000000   15.045800\n",
              "75%     35.000000            1.000000    0.000000   31.387500\n",
              "max     80.000000            8.000000    5.000000  512.329200"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6JnzXA3sSyZ8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "MEAN = desc.T[\"mean\"].values\n",
        "STD = desc.T[\"std\"].values"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JI5FSwmGTBGT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def normalize_numeric_data(data, mean, std):\n",
        "  return (data-mean)/std"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dnrdAuCsTIfF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "068a4bab-dfec-4e76-d70d-05793fbf4c97"
      },
      "source": [
        "import functools\n",
        "normalizer = functools.partial(normalize_numeric_data, mean=MEAN, std=STD)\n",
        "numeric_column = tf.feature_column.numeric_column('numeric', normalizer_fn=normalizer, shape=[len(NUMERIC_FEATURES)])\n",
        "numeric_column"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "NumericColumn(key='numeric', shape=(4,), default_value=None, dtype=tf.float32, normalizer_fn=functools.partial(<function normalize_numeric_data at 0x7efce88597b8>, mean=array([29.631,  0.545,  0.38 , 34.385]), std=array([12.512,  1.151,  0.793, 54.598])))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zld0RPzoT7kk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "ace27629-df5d-4e48-bd60-514d3bd0abd5"
      },
      "source": [
        "example_batch['numeric']"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: id=852, shape=(5, 4), dtype=float32, numpy=\n",
              "array([[39.   ,  0.   ,  0.   , 26.   ],\n",
              "       [ 4.   ,  0.   ,  2.   , 22.025],\n",
              "       [15.   ,  1.   ,  0.   , 14.454],\n",
              "       [47.   ,  1.   ,  1.   , 52.554],\n",
              "       [21.   ,  0.   ,  0.   ,  7.775]], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VzBTAwxPT_cZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "d33c2ec7-cf80-4b15-a266-b4e10288fc1a"
      },
      "source": [
        "numeric_layer = tf.keras.layers.DenseFeatures(numeric_column)\n",
        "numeric_layer(example_batch).numpy()"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0.749, -0.474, -0.479, -0.154],\n",
              "       [-2.049, -0.474,  2.043, -0.226],\n",
              "       [-1.169,  0.395, -0.479, -0.365],\n",
              "       [ 1.388,  0.395,  0.782,  0.333],\n",
              "       [-0.69 , -0.474, -0.479, -0.487]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hKuhNA3vVNcl",
        "colab_type": "text"
      },
      "source": [
        "#### Categorical Columns"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "33CVZHWmUWRY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "CATEGORIES = {\n",
        "    'sex': ['male', 'female'],\n",
        "    'class' : ['First', 'Second', 'Third'],\n",
        "    'deck' : ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J'],\n",
        "    'embark_town' : ['Cherbourg', 'Southhampton', 'Queenstown'],\n",
        "    'alone' : ['y', 'n']\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w_GnSP_6VE_6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "categorical_columns = []\n",
        "for feature, vocab in CATEGORIES.items():\n",
        "  cat_col = tf.feature_column.categorical_column_with_vocabulary_list(\n",
        "      key=feature, vocabulary_list=vocab\n",
        "  )\n",
        "  cat_col = tf.feature_column.indicator_column(cat_col)\n",
        "  categorical_columns.append(cat_col)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pEok0WL_VjI5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "a81a6ccc-619e-4e76-e259-140b419ec21a"
      },
      "source": [
        "categorical_columns"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[IndicatorColumn(categorical_column=VocabularyListCategoricalColumn(key='sex', vocabulary_list=('male', 'female'), dtype=tf.string, default_value=-1, num_oov_buckets=0)),\n",
              " IndicatorColumn(categorical_column=VocabularyListCategoricalColumn(key='class', vocabulary_list=('First', 'Second', 'Third'), dtype=tf.string, default_value=-1, num_oov_buckets=0)),\n",
              " IndicatorColumn(categorical_column=VocabularyListCategoricalColumn(key='deck', vocabulary_list=('A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J'), dtype=tf.string, default_value=-1, num_oov_buckets=0)),\n",
              " IndicatorColumn(categorical_column=VocabularyListCategoricalColumn(key='embark_town', vocabulary_list=('Cherbourg', 'Southhampton', 'Queenstown'), dtype=tf.string, default_value=-1, num_oov_buckets=0)),\n",
              " IndicatorColumn(categorical_column=VocabularyListCategoricalColumn(key='alone', vocabulary_list=('y', 'n'), dtype=tf.string, default_value=-1, num_oov_buckets=0))]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I15bwGBEVxnO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "categorical_layer = tf.keras.layers.DenseFeatures(categorical_columns)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iWzs537wWIDo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2924bdfa-4640-4dad-8cc2-a0549953cd10"
      },
      "source": [
        "print(categorical_layer(example_batch).numpy()[0])"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i3eDTjvbXQCb",
        "colab_type": "text"
      },
      "source": [
        "### Combined Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UFOIyEOKXdYE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "8ba9f6a3-3d37-4845-9458-7960db9eb88e"
      },
      "source": [
        "preprocessing_layer = tf.keras.layers.DenseFeatures([numeric_column]+categorical_columns)\n",
        "print(preprocessing_layer(example_batch).numpy()[0])"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[ 1.     0.     0.     1.     0.     0.     0.     0.     0.     0.\n",
            "  0.     0.     0.     0.     0.     0.     0.     0.     0.749 -0.474\n",
            " -0.479 -0.154  1.     0.   ]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RKnL31t9Z5-3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "strategy = tf.distribute.MirroredStrategy(cross_device_ops=tf.distribute.NcclAllReduce())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ufNQYt3X5Pb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with strategy.scope():\n",
        "  model = tf.keras.Sequential([\n",
        "                              preprocessing_layer,\n",
        "                              tf.keras.layers.Dense(256, activation=tf.nn.relu),\n",
        "                              tf.keras.layers.Dense(128, activation=tf.nn.relu),\n",
        "                              tf.keras.layers.Dense(1, activation=tf.nn.sigmoid)\n",
        "  ])\n",
        "\n",
        "  model.compile(\n",
        "      loss='binary_crossentropy',\n",
        "      optimizer='adam',\n",
        "      metrics=['accuracy']\n",
        "  )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pdgcOgRqYLVr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_data = packed_train_data.shuffle(500)\n",
        "test_data = packed_test_data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AQ1UJcSPZVbz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        },
        "outputId": "ec06c912-3441-49d7-ec53-48be8b358ee5"
      },
      "source": [
        "with strategy.scope():\n",
        "  model.fit(train_data, \n",
        "            epochs=50, \n",
        "            validation_data=test_data, \n",
        "            verbose=1,\n",
        "            callbacks=[tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss',patience=2,verbose=1),\n",
        "                       tf.keras.callbacks.EarlyStopping(monitor='val_loss',patience=5,verbose=1)])"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "126/126 [==============================] - 4s 29ms/step - loss: 0.3367 - accuracy: 0.8628 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00\n",
            "Epoch 2/50\n",
            "126/126 [==============================] - 1s 9ms/step - loss: 0.3384 - accuracy: 0.8628 - val_loss: 0.4202 - val_accuracy: 0.8409\n",
            "Epoch 3/50\n",
            "126/126 [==============================] - 1s 9ms/step - loss: 0.3476 - accuracy: 0.8628 - val_loss: 0.4162 - val_accuracy: 0.8409\n",
            "Epoch 4/50\n",
            "126/126 [==============================] - 1s 9ms/step - loss: 0.3411 - accuracy: 0.8628 - val_loss: 0.4166 - val_accuracy: 0.8409\n",
            "Epoch 5/50\n",
            "49/53 [==========================>...] - ETA: 0s - loss: 0.3364 - accuracy: 0.8694\n",
            "Epoch 00005: ReduceLROnPlateau reducing learning rate to 1.000000142800998e-27.\n",
            "126/126 [==============================] - 1s 9ms/step - loss: 0.3402 - accuracy: 0.8628 - val_loss: 0.4171 - val_accuracy: 0.8409\n",
            "Epoch 6/50\n",
            "126/126 [==============================] - 1s 9ms/step - loss: 0.3544 - accuracy: 0.8628 - val_loss: 0.4168 - val_accuracy: 0.8409\n",
            "Epoch 7/50\n",
            "50/53 [===========================>..] - ETA: 0s - loss: 0.3459 - accuracy: 0.8360\n",
            "Epoch 00007: ReduceLROnPlateau reducing learning rate to 1.0000001235416984e-28.\n",
            "126/126 [==============================] - 1s 9ms/step - loss: 0.3460 - accuracy: 0.8628 - val_loss: 0.4166 - val_accuracy: 0.8409\n",
            "Epoch 8/50\n",
            "126/126 [==============================] - 1s 9ms/step - loss: 0.3448 - accuracy: 0.8628 - val_loss: 0.4165 - val_accuracy: 0.8409\n",
            "Epoch 00008: early stopping\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kDBfUthjZv_d",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "f6283262-43b9-432d-cba3-a79288762b71"
      },
      "source": [
        "test_loss, test_accuracy = model.evaluate(test_data)\n",
        "\n",
        "print('\\n\\nTest Loss {:.2f}, Test Accuracy {:.2f}'.format(test_loss, test_accuracy))"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "53/53 [==============================] - 2s 35ms/step - loss: 0.4178 - accuracy: 0.8409\n",
            "\n",
            "\n",
            "Test Loss 0.42, Test Accuracy 0.84\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VULAvgsNbZWE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "e865eae8-04a3-4ffe-b88a-06bb4ba68ea3"
      },
      "source": [
        "predictions = model.predict(test_data)\n",
        "\n",
        "for prediction, survived in zip(predictions[:10], list(test_data)[0][1][:10]):\n",
        "  print(\"Predicted survival: {:.2%}\".format(prediction[0]),\n",
        "        \" | Actual outcome: \",\n",
        "        (\"SURVIVED\" if bool(survived) else \"DIED\"))"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Predicted survival: 33.84%  | Actual outcome:  DIED\n",
            "Predicted survival: 30.88%  | Actual outcome:  DIED\n",
            "Predicted survival: 19.34%  | Actual outcome:  SURVIVED\n",
            "Predicted survival: 82.43%  | Actual outcome:  DIED\n",
            "Predicted survival: 99.06%  | Actual outcome:  DIED\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}