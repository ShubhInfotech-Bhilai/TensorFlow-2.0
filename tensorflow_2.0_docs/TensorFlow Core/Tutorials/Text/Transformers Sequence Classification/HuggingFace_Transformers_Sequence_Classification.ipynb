{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HuggingFace Transformers - Sequence Classification.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sourcecode369/TensorFlow-2.0/blob/master/tensorflow_2.0_docs/TensorFlow%20Core/Tutorials/Text/Transformers%20Sequence%20Classification/HuggingFace_Transformers_Sequence_Classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hWrc3Kvx8CFW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "5bae09e6-9b58-4b4d-dd15-41b11f27ad48"
      },
      "source": [
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "print(tf.__version__)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 2.x selected.\n",
            "2.0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_6jwKdvVfd3o",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 377
        },
        "outputId": "7007a88a-661a-4cac-ac1b-0edff0d4f163"
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.6/dist-packages (2.1.1)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (from transformers) (0.0.35)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from transformers) (4.28.1)\n",
            "Requirement already satisfied: numpy in /tensorflow-2.0.0/python3.6 (from transformers) (1.17.3)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.6/dist-packages (from transformers) (0.1.83)\n",
            "Requirement already satisfied: requests in /tensorflow-2.0.0/python3.6 (from transformers) (2.22.0)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.11.1)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from transformers) (1.10.7)\n",
            "Requirement already satisfied: six in /tensorflow-2.0.0/python3.6 (from sacremoses->transformers) (1.13.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.14.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.0)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /tensorflow-2.0.0/python3.6 (from requests->transformers) (2.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /tensorflow-2.0.0/python3.6 (from requests->transformers) (2019.9.11)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /tensorflow-2.0.0/python3.6 (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /tensorflow-2.0.0/python3.6 (from requests->transformers) (1.25.6)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.9.4)\n",
            "Requirement already satisfied: botocore<1.14.0,>=1.13.7 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (1.13.7)\n",
            "Requirement already satisfied: s3transfer<0.3.0,>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.2.1)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1; python_version >= \"2.7\" in /usr/local/lib/python3.6/dist-packages (from botocore<1.14.0,>=1.13.7->boto3->transformers) (2.6.1)\n",
            "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.14.0,>=1.13.7->boto3->transformers) (0.15.2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WOQP8ss0flb8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from transformers import TFBertForSequenceClassification, BertTokenizer, TFRobertaForSequenceClassification, RobertaTokenizer, TFGPT2Model, GPT2Tokenizer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6iMucqE7x1CM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "c24d491d-bd0f-4b5d-c761-1dbafec1af1b"
      },
      "source": [
        "bert_model = TFBertForSequenceClassification.from_pretrained(\"bert-base-cased\")\n",
        "bert_tokenizer = BertTokenizer.from_pretrained(\"bert-base-cased\")\n",
        "\n",
        "roberta_model = TFRobertaForSequenceClassification.from_pretrained(\"roberta-base\")\n",
        "roberta_tokenizer = RobertaTokenizer.from_pretrained(\"roberta-base\")"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "A sequence with no special tokens has been passed to the RoBERTa model. This model requires special tokens in order to work. Please specify add_special_tokens=True in your encoding.\n",
            "A sequence with no special tokens has been passed to the RoBERTa model. This model requires special tokens in order to work. Please specify add_special_tokens=True in your encoding.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6op4zF5PyCTk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sequence = \"Systolic arrays are cool. This is cool too. Artificial Intelligence is the coolest of all.\"\n",
        "bert_tokenized_sequence = bert_tokenizer.tokenize(sequence)\n",
        "roberta_tokenized_sequence = roberta_tokenizer.tokenize(sequence)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yqlkaFKTyxTh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "223079a4-7afe-4542-a578-f20873a68778"
      },
      "source": [
        "print(f\"Bert: {bert_tokenized_sequence}\")\n",
        "print(f\"Robert: {roberta_tokenized_sequence}\")"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Bert: ['S', '##ys', '##to', '##lic', 'array', '##s', 'are', 'cool', '.', 'This', 'is', 'cool', 'too', '.', 'Art', '##ific', '##ial', 'Intelligence', 'is', 'the', 'cool', '##est', 'of', 'all', '.']\n",
            "Robert: ['Sy', 'st', 'olic', 'Ġarrays', 'Ġare', 'Ġcool', '.', 'ĠThis', 'Ġis', 'Ġcool', 'Ġtoo', '.', 'ĠArtificial', 'ĠIntelligence', 'Ġis', 'Ġthe', 'Ġcoolest', 'Ġof', 'Ġall', '.']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rzql26BQz1UU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# !pip install --upgrade tensorflow-gpu"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ca_H-DQszAH9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ec124273-72be-4f7c-dd49-a271266466cb"
      },
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "tfds.disable_progress_bar()\n",
        "print(\"Tensorflow version: \",tf.__version__)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tensorflow version:  2.0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JL5caPPnzwxj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "90f7378a-e216-48fc-84a5-ab7d751a119e"
      },
      "source": [
        "data = tfds.load('glue/mrpc')\n",
        "\n",
        "train_dataset = data[\"train\"]\n",
        "validation_dataset = data[\"validation\"]"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:absl:Overwrite dataset info from restored data version.\n",
            "INFO:absl:Reusing dataset glue (/root/tensorflow_datasets/glue/mrpc/0.0.2)\n",
            "INFO:absl:Constructing tf.data.Dataset for split None, from /root/tensorflow_datasets/glue/mrpc/0.0.2\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S97X8tPp0w-A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "example = list(train_dataset.__iter__())[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M11uiNkl03Ut",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "d9bada7e-92e2-4326-8b3e-bfb6b0d94115"
      },
      "source": [
        "example"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'idx': <tf.Tensor: id=13353, shape=(), dtype=int32, numpy=201>,\n",
              " 'label': <tf.Tensor: id=13354, shape=(), dtype=int64, numpy=1>,\n",
              " 'sentence1': <tf.Tensor: id=13355, shape=(), dtype=string, numpy=b'Tibco has used the Rendezvous name since 1994 for several of its technology products , according to the Palo Alto , California company .'>,\n",
              " 'sentence2': <tf.Tensor: id=13356, shape=(), dtype=string, numpy=b'Tibco has used the Rendezvous name since 1994 for several of its technology products , it said .'>}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l-Ar9iW6040e",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "bbff2cf3-a40b-4a31-da5a-2a062fb8c76a"
      },
      "source": [
        "train_dataset.element_spec"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'idx': TensorSpec(shape=(), dtype=tf.int32, name=None),\n",
              " 'label': TensorSpec(shape=(), dtype=tf.int64, name=None),\n",
              " 'sentence1': TensorSpec(shape=(), dtype=tf.string, name=None),\n",
              " 'sentence2': TensorSpec(shape=(), dtype=tf.string, name=None)}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Eke953b509sE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "1214ecda-4bce-45f6-cf81-2b0287065134"
      },
      "source": [
        "next(iter(train_dataset))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'idx': <tf.Tensor: id=28030, shape=(), dtype=int32, numpy=201>,\n",
              " 'label': <tf.Tensor: id=28031, shape=(), dtype=int64, numpy=1>,\n",
              " 'sentence1': <tf.Tensor: id=28032, shape=(), dtype=string, numpy=b'Tibco has used the Rendezvous name since 1994 for several of its technology products , according to the Palo Alto , California company .'>,\n",
              " 'sentence2': <tf.Tensor: id=28033, shape=(), dtype=string, numpy=b'Tibco has used the Rendezvous name since 1994 for several of its technology products , it said .'>}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9fRYCa6S1CqD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "seq0 = example['sentence1'].numpy().decode('utf8')\n",
        "seq1 = example['sentence2'].numpy().decode('utf8')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RfIlDBnG1O_V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "encoded_bert_sequence = bert_tokenizer.encode(seq0, seq1, add_special_tokens=True, max_length=128)\n",
        "encoded_roberta_sequence = roberta_tokenizer.encode(seq0, seq1, add_special_tokens=True, max_length=128)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dpeGrqI210Tu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "0660d501-53d6-47d1-92ee-84931eb598bb"
      },
      "source": [
        "print(f\"Bert tokenizer separator: {bert_tokenizer.sep_token_id} {bert_tokenizer.cls_token_id}\")\n",
        "print(f\"RoBerta tokenizer separator: {roberta_tokenizer.sep_token_id} {roberta_tokenizer.cls_token_id}\")"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Bert tokenizer separator: 102 101\n",
            "RoBerta tokenizer separator: 2 0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DKCXNWDC1004",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "bert_special_tokens = [bert_tokenizer.cls_token_id, bert_tokenizer.sep_token_id]\n",
        "roberta_special_tokens = [roberta_tokenizer.cls_token_id, roberta_tokenizer.sep_token_id]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LdWSHZY03q-8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def print_in_red(string):\n",
        "  print(\"\\033[91m\" + str(string) + \"\\033[0m\", end=' ')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4xKl7W7p3sc_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "e3532691-3248-4694-db56-917256e4f15f"
      },
      "source": [
        "print(\"\\nBERT tokenized sequence\")\n",
        "output = [print_in_red(tok) if tok in bert_special_tokens else print(tok, end=' ') for tok in encoded_bert_sequence]\n",
        "\n",
        "print(\"\\nRoBERTa tokenized sequence\")\n",
        "output = [print_in_red(tok) if tok in roberta_special_tokens else print(tok, end=' ') for tok in encoded_roberta_sequence]"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "BERT tokenized sequence\n",
            "\u001b[91m101\u001b[0m 157 13292 2528 1144 1215 1103 16513 15125 11944 1271 1290 1898 1111 1317 1104 1157 2815 2982 117 2452 1106 1103 19585 2858 17762 117 1756 1419 119 \u001b[91m102\u001b[0m 157 13292 2528 1144 1215 1103 16513 15125 11944 1271 1290 1898 1111 1317 1104 1157 2815 2982 117 1122 1163 119 \u001b[91m102\u001b[0m \n",
            "RoBERTa tokenized sequence\n",
            "\u001b[91m0\u001b[0m 565 1452 876 34 341 5 29110 42057 766 187 8148 13 484 9 63 806 785 2156 309 7 5 21065 18402 2156 886 138 479 \u001b[91m2\u001b[0m \u001b[91m2\u001b[0m 565 1452 876 34 341 5 29110 42057 766 187 8148 13 484 9 63 806 785 2156 24 26 479 \u001b[91m2\u001b[0m "
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uln6-Y3I37Xu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from transformers import glue_convert_examples_to_features\n",
        "\n",
        "bert_train_dataset = glue_convert_examples_to_features(train_dataset, bert_tokenizer, 128, 'mrpc')\n",
        "bert_train_dataset = bert_train_dataset.shuffle(100).batch(32).repeat(2).prefetch(tf.data.experimental.AUTOTUNE)\n",
        "\n",
        "bert_validation_dataset = glue_convert_examples_to_features(validation_dataset, bert_tokenizer, 128, 'mrpc')\n",
        "bert_validation_dataset = bert_validation_dataset.batch(64)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JftM9pIb5Mb5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def delete_token_type_ids(example, label):\n",
        "  del example[\"token_type_ids\"]\n",
        "  return example, label"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "auQlveUh5gOY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "roberta_train_dataset = glue_convert_examples_to_features(train_dataset,roberta_tokenizer,128,'mrpc')\n",
        "roberta_train_dataset = roberta_train_dataset.map(delete_token_type_ids,tf.data.experimental.AUTOTUNE).shuffle(100).batch(32).repeat(2).prefetch(tf.data.experimental.AUTOTUNE)\n",
        "\n",
        "roberta_validation_dataset = glue_convert_examples_to_features(validation_dataset, roberta_tokenizer, 128,'mrpc')\n",
        "roberta_validation_dataset = roberta_validation_dataset.map(delete_token_type_ids, tf.data.experimental.AUTOTUNE).batch(64).prefetch(tf.data.experimental.AUTOTUNE)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z8ynAoFn6cS8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "optimizer = tf.keras.optimizers.Adam(learning_rate=3e-5, epsilon=1e-08, clipnorm=1.0)\n",
        "loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "metric = tf.keras.metrics.SparseCategoricalAccuracy('accuracy')\n",
        "\n",
        "bert_model.compile(optimizer=optimizer, loss=loss, metrics=[metric])\n",
        "roberta_model.compile(optimizer=optimizer, loss=loss, metrics=[metric])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9tqL8yAc7mf7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "outputId": "51921812-eb93-4848-913d-2b51d40d044d"
      },
      "source": [
        "# Now for the beauty of TensorFlow and Keras\n",
        "bert_history = bert_model.fit(bert_train_dataset, \n",
        "                              epochs=1, \n",
        "                              validation_data=bert_validation_dataset,\n",
        "                              callbacks = [\n",
        "                                           tf.keras.callbacks.TensorBoard(log_dir='bert_logs/'),                                    \n",
        "                              ])"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r      1/Unknown - 19s 19s/step - loss: 0.6530 - accuracy: 0.5938WARNING:tensorflow:Method (on_train_batch_end) is slow compared to the batch update (3.185630). Check your callbacks.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Method (on_train_batch_end) is slow compared to the batch update (3.185630). Check your callbacks.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "230/230 [==============================] - 214s 929ms/step - loss: 0.4584 - accuracy: 0.7871 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xVhF6mrSB0Uf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# roberta_history = roberta_model.fit(roberta_train_dataset, \n",
        "#                               epochs=1, \n",
        "#                               validation_data=roberta_validation_dataset,\n",
        "#                               callbacks = [\n",
        "#                                            tf.keras.callbacks.TensorBoard(log_dir='roberta_logs/'),\n",
        "#                               ])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IqvqtNEegprx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "0aefaa14-5c1e-463e-a0b8-5f15e7832670"
      },
      "source": [
        "bert_model.evaluate(bert_validation_dataset, verbose=1)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "7/7 [==============================] - 3s 486ms/step - loss: 0.4083 - accuracy: 0.8309\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.4082875038896288, 0.8308824]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tJEHUBXCgsdc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}