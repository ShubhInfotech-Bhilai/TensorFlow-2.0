{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TensorFlow 2.0 - Data Input Pipelines - Performance with tf.data.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sourcecode369/TensorFlow-2.0/blob/master/tensorflow_2.0_docs/TensorFlow%20Core/Guide/Data%20Input%20Pipelines/Performance%20with%20tf.data/TensorFlow_2_0_Data_Input_Pipelines_Performance_with_tf_data.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qEIn0aAOOU71",
        "colab_type": "text"
      },
      "source": [
        "### Overview"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AzlpfFpOPABn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 680
        },
        "outputId": "0cbfa8f9-bd0f-44e5-e6ea-eb4af8c9ee88"
      },
      "source": [
        "!pip install --upgrade tensorflow\n",
        "import tensorflow as tf\n",
        "print(\"TensorFlow version: \",tf.__version__)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/46/0f/7bd55361168bb32796b360ad15a25de6966c9c1beb58a8e30c01c8279862/tensorflow-2.0.0-cp36-cp36m-manylinux2010_x86_64.whl (86.3MB)\n",
            "\u001b[K     |████████████████████████████████| 86.3MB 1.9MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.1.0)\n",
            "Requirement already satisfied, skipping upgrade: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.16.5)\n",
            "Collecting tensorflow-estimator<2.1.0,>=2.0.0 (from tensorflow)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/95/00/5e6cdf86190a70d7382d320b2b04e4ff0f8191a37d90a422a2f8ff0705bb/tensorflow_estimator-2.0.0-py2.py3-none-any.whl (449kB)\n",
            "\u001b[K     |████████████████████████████████| 450kB 44.7MB/s \n",
            "\u001b[?25hCollecting tensorboard<2.1.0,>=2.0.0 (from tensorflow)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9b/a6/e8ffa4e2ddb216449d34cfcb825ebb38206bee5c4553d69e7bc8bc2c5d64/tensorboard-2.0.0-py3-none-any.whl (3.8MB)\n",
            "\u001b[K     |████████████████████████████████| 3.8MB 34.3MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.1.7)\n",
            "Requirement already satisfied, skipping upgrade: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.8.0)\n",
            "Requirement already satisfied, skipping upgrade: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (3.1.0)\n",
            "Requirement already satisfied, skipping upgrade: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.1.0)\n",
            "Requirement already satisfied, skipping upgrade: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (3.7.1)\n",
            "Requirement already satisfied, skipping upgrade: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.15.0)\n",
            "Requirement already satisfied, skipping upgrade: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.11.2)\n",
            "Requirement already satisfied, skipping upgrade: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.8.0)\n",
            "Requirement already satisfied, skipping upgrade: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.12.0)\n",
            "Requirement already satisfied, skipping upgrade: gast==0.2.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.2.2)\n",
            "Requirement already satisfied, skipping upgrade: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.33.6)\n",
            "Requirement already satisfied, skipping upgrade: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.0.8)\n",
            "Requirement already satisfied, skipping upgrade: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow) (3.1.1)\n",
            "Requirement already satisfied, skipping upgrade: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow) (41.2.0)\n",
            "Requirement already satisfied, skipping upgrade: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow) (0.16.0)\n",
            "Requirement already satisfied, skipping upgrade: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.8->tensorflow) (2.8.0)\n",
            "Installing collected packages: tensorflow-estimator, tensorboard, tensorflow\n",
            "  Found existing installation: tensorflow-estimator 1.15.1\n",
            "    Uninstalling tensorflow-estimator-1.15.1:\n",
            "      Successfully uninstalled tensorflow-estimator-1.15.1\n",
            "  Found existing installation: tensorboard 1.15.0\n",
            "    Uninstalling tensorboard-1.15.0:\n",
            "      Successfully uninstalled tensorboard-1.15.0\n",
            "  Found existing installation: tensorflow 1.15.0rc3\n",
            "    Uninstalling tensorflow-1.15.0rc3:\n",
            "      Successfully uninstalled tensorflow-1.15.0rc3\n",
            "Successfully installed tensorboard-2.0.0 tensorflow-2.0.0 tensorflow-estimator-2.0.0\n",
            "TensorFlow version:  2.0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u7IujmscP9o1",
        "colab_type": "text"
      },
      "source": [
        "### Structure of an input pipeline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M_7B2s2PQA_c",
        "colab_type": "text"
      },
      "source": [
        "> A typical TensorFlow training input pipeline can be framed as an ETL process:\n",
        "\n",
        "1. **Extract:** Read data from memory (NumPy) or persistent storage -- either local (HDD or SSD) or remote (e.g. GCS or HDFS).\n",
        "\n",
        "2. **Transform:** Use CPU to parse and perform preprocessing operations on the data such as shuffling, batching, and domain specific transformations such as image decompression and augmentation, text vectorization, or video temporal sampling.\n",
        "\n",
        "3. **Load:** Load the transformed data onto the accelerator device(s) (e.g. GPU(s) or TPU(s)) that execute the machine learning model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7zmGv6MaOL8T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def parse_fn(example):\n",
        "  \"Parse TFExample records and perform simple data augmentation.\"\n",
        "  example_fmt = {\n",
        "    \"image\": tf.FixedLengthFeature((), tf.string, \"\"),\n",
        "    \"label\": tf.FixedLengthFeature((), tf.int64, -1)\n",
        "  }\n",
        "  parsed = tf.parse_single_example(example, example_fmt)\n",
        "  image = tf.io.image.decode_image(parsed[\"image\"])\n",
        "  image = _augment_helper(image)  # augments image using slice, reshape, resize_bilinear\n",
        "  return image, parsed[\"label\"]\n",
        "\n",
        "def make_dataset():\n",
        "  dataset = tf.data.TFRecordDataset(\"/path/to/dataset/train-*.tfrecord\")\n",
        "  dataset = dataset.shuffle(buffer_size=FLAGS.shuffle_buffer_size)\n",
        "  dataset = dataset.map(map_func=parse_fn)\n",
        "  dataset = dataset.batch(batch_size=FLAGS.batch_size)\n",
        "  return dataset"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HophfZKcP3Rd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "c0a1d7e6-2ae9-4284-ee34-568f3c30ac61"
      },
      "source": [
        "tf.config.experimental.list_physical_devices()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU'),\n",
              " PhysicalDevice(name='/physical_device:XLA_CPU:0', device_type='XLA_CPU')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8JmvzWEtQX8C",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "960faa14-faf0-44f8-c90c-ed2da1e1a772"
      },
      "source": [
        "tf.test.is_gpu_available()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ueKpTiWxQeMa",
        "colab_type": "text"
      },
      "source": [
        "### Optimizing Performance"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IXBwgTE-Qm4C",
        "colab_type": "text"
      },
      "source": [
        "#### Pipelining"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sFUJ9cslQ9UL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### \n",
        "# dataset = dataset.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
        "###"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DHqmaoctRhMa",
        "colab_type": "text"
      },
      "source": [
        "#### Parallelize data transformation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0u-AFEbeRysL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "###\n",
        "# dataset = dataset.prefetch(map_func = parse_fn, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
        "###"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ql9SWJzISlIQ",
        "colab_type": "text"
      },
      "source": [
        "#### Parallelize data extraction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LgWNNE6eSnx6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "###\n",
        "# files = tf.data.list_files(\"/path/to/dataset/train-*.tfrecord\")  \n",
        "# dataset = files.interleave(\n",
        "# tf.data.TFRecordDataset, cycle_length = FLAGS.num_parallel_reads,\n",
        "# num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
        "###"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "niIOokilT86G",
        "colab_type": "text"
      },
      "source": [
        "### Performance considerations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TQ3AU37rUCdX",
        "colab_type": "text"
      },
      "source": [
        "The tf.data API is designed around composable transformations to provide its users with flexibility. Although many of these transformations are commutative, the ordering of certain transformations has performance implications."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3d3zNRmlULBH",
        "colab_type": "text"
      },
      "source": [
        "#### Map and batch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jCZZ3rmxUgpI",
        "colab_type": "text"
      },
      "source": [
        "apply the batch transformation before the map transformation."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lt3dnZRDVeF0",
        "colab_type": "text"
      },
      "source": [
        "#### Map and cache"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Kt57V4wVgDM",
        "colab_type": "text"
      },
      "source": [
        "If the user-defined function passed into the map transformation is expensive, apply the cache transformation after the map transformation as long as the resulting dataset can still fit into memory or local storage. If the user-defined function increases the space required to store the dataset beyond the cache capacity, consider pre-processing your data before your training job to reduce resource usage."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "53VAQ1imV1Nm",
        "colab_type": "text"
      },
      "source": [
        "#### Map and interleave/ prefetch/ shuffle"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CmdV682BV5Ud",
        "colab_type": "text"
      },
      "source": [
        "A number of transformations, including interleave, prefetch, and shuffle, maintain an internal buffer of elements. If the user-defined function passed into the map transformation changes the size of the elements, then the ordering of the map transformation and the transformations that buffer elements affects the memory usage. In general, we recommend choosing the order that results in lower memory footprint, unless different ordering is desirable for performance (for example, to enable fusing of the map and batch transformations)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x543cKi0WCFG",
        "colab_type": "text"
      },
      "source": [
        "#### Shuffle and Repeat"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SbXD64UPWoQX",
        "colab_type": "text"
      },
      "source": [
        "If the repeat transformation is applied before the shuffle transformation, then the epoch boundaries are blurred. That is, certain elements can be repeated before other elements appear even once. On the other hand, if the shuffle transformation is applied before the repeat transformation, then performance might slow down at the beginning of each epoch related to initialization of the internal state of the shuffle transformation. In other words, the former (repeat before shuffle) provides better performance, while the latter (shuffle before repeat) provides stronger ordering guarantees."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7zNY6I4lXGLw",
        "colab_type": "text"
      },
      "source": [
        "### Best Practises using tf.data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D1Qg64GgXeqZ",
        "colab_type": "text"
      },
      "source": [
        "> Here is a summary of the best practices for designing performant TensorFlow input pipelines:\n",
        "\n",
        "1. Use the prefetch transformation to overlap the work of a producer and consumer. In particular, we recommend adding prefetch to the end of your input pipeline to overlap the transformations performed on the CPU with the training done on the accelerator. Either manually tuning the buffer size, or using tf.data.experimental.AUTOTUNE to delegate the decision to the tf.data runtime.\n",
        "\n",
        "2. Parallelize the map transformation by setting the num_parallel_calls argument. Either manually tuning the level of parallelism, or using tf.data.experimental.AUTOTUNE to delegate the decision to the tf.data runtime.\n",
        "\n",
        "3. If you are working with data stored remotely and / or requiring deserialization, we recommend using the interleave transformation to parallelize the reading (and deserialization) of data from different files.\n",
        "\n",
        "4. Vectorize cheap user-defined functions passed in to the map transformation to amortize the overhead associated with scheduling and executing the function.\n",
        "\n",
        "5. If your data can fit into memory, use the cache transformation to cache it in memory during the first epoch, so that subsequent epochs can avoid the overhead associated with reading, parsing, and transforming it.\n",
        "\n",
        "6. If your pre-processing increases the size of your data, we recommend applying the interleave, prefetch, and shuffle first (if possible) to reduce memory usage.\n",
        "\n",
        "7. We recommend applying the shuffle transformation before the repeat transformation."
      ]
    }
  ]
}