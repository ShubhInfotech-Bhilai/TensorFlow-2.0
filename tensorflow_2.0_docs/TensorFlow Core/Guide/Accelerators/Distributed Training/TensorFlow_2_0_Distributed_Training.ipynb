{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TensorFlow 2.0 Accelarators Distributed Training.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sourcecode369/TensorFlow-2.0/blob/master/tensorflow_2.0_docs/TensorFlow%20Core/Guide/Accelerators/Distributed%20Training/TensorFlow_2_0_Distributed_Training.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jRqh877K0-cH",
        "colab_type": "text"
      },
      "source": [
        "### Overview "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LD16afZVfRvo",
        "colab_type": "text"
      },
      "source": [
        "> `tf.distribute.Strategy is a TensorFlow API to distribute training across multiple GPUs, multiple machines or TPUs. Using this API, you can distribute your existing models and training code with minimal code changes.`\n",
        "\n",
        "    tf.distribute.Strategy has been designed with these key goals in mind:\n",
        "\n",
        "* `Easy to use and support multiple user segments, including researchers, ML engineers, etc.`\n",
        "* `Provide good performance out of the box.`\n",
        "* `Easy switching between strategies.`\n",
        "\n",
        "\n",
        "> `Use tf.distribute.Strategy with a high-level API like Keras, and can also be used to distribute custom training loops (and, in general, any computation using TensorFlow).`\n",
        "\n",
        "\n",
        "> `In TensorFlow 2.0, you can execute your programs eagerly, or in a graph using tf.function. tf.distribute.Strategy intends to support both these modes of execution. Although we discuss training most of the time in this guide, this API can also be used for distributing evaluation and prediction on different platforms.`\n",
        "\n",
        "> `You can use tf.distribute.Strategy with very few changes to your code, because we have changed the underlying components of TensorFlow to become strategy-aware. This includes variables, layers, models, optimizers, metrics, summaries, and checkpoints.`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BnA2TdIUfzj6",
        "colab_type": "code",
        "outputId": "3268c788-1734-4442-e720-6c9c4ec5af19",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 635
        }
      },
      "source": [
        "!pip install --upgrade tensorflow"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/46/0f/7bd55361168bb32796b360ad15a25de6966c9c1beb58a8e30c01c8279862/tensorflow-2.0.0-cp36-cp36m-manylinux2010_x86_64.whl (86.3MB)\n",
            "\u001b[K     |████████████████████████████████| 86.3MB 36.3MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.16.5)\n",
            "Requirement already satisfied, skipping upgrade: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.12.0)\n",
            "Requirement already satisfied, skipping upgrade: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (3.7.1)\n",
            "Requirement already satisfied, skipping upgrade: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.15.0)\n",
            "Requirement already satisfied, skipping upgrade: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.1.0)\n",
            "Requirement already satisfied, skipping upgrade: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.1.0)\n",
            "Requirement already satisfied, skipping upgrade: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.11.2)\n",
            "Requirement already satisfied, skipping upgrade: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.8.0)\n",
            "Requirement already satisfied, skipping upgrade: gast==0.2.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.2.2)\n",
            "Collecting tensorflow-estimator<2.1.0,>=2.0.0 (from tensorflow)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/95/00/5e6cdf86190a70d7382d320b2b04e4ff0f8191a37d90a422a2f8ff0705bb/tensorflow_estimator-2.0.0-py2.py3-none-any.whl (449kB)\n",
            "\u001b[K     |████████████████████████████████| 450kB 39.4MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.0.8)\n",
            "Requirement already satisfied, skipping upgrade: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.33.6)\n",
            "Requirement already satisfied, skipping upgrade: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (3.1.0)\n",
            "Collecting tensorboard<2.1.0,>=2.0.0 (from tensorflow)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9b/a6/e8ffa4e2ddb216449d34cfcb825ebb38206bee5c4553d69e7bc8bc2c5d64/tensorboard-2.0.0-py3-none-any.whl (3.8MB)\n",
            "\u001b[K     |████████████████████████████████| 3.8MB 32.4MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.8.0)\n",
            "Requirement already satisfied, skipping upgrade: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.1.7)\n",
            "Requirement already satisfied, skipping upgrade: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow) (41.2.0)\n",
            "Requirement already satisfied, skipping upgrade: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.8->tensorflow) (2.8.0)\n",
            "Requirement already satisfied, skipping upgrade: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow) (0.16.0)\n",
            "Requirement already satisfied, skipping upgrade: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow) (3.1.1)\n",
            "Installing collected packages: tensorflow-estimator, tensorboard, tensorflow\n",
            "  Found existing installation: tensorflow-estimator 1.15.1\n",
            "    Uninstalling tensorflow-estimator-1.15.1:\n",
            "      Successfully uninstalled tensorflow-estimator-1.15.1\n",
            "  Found existing installation: tensorboard 1.15.0\n",
            "    Uninstalling tensorboard-1.15.0:\n",
            "      Successfully uninstalled tensorboard-1.15.0\n",
            "  Found existing installation: tensorflow 1.15.0rc3\n",
            "    Uninstalling tensorflow-1.15.0rc3:\n",
            "      Successfully uninstalled tensorflow-1.15.0rc3\n",
            "Successfully installed tensorboard-2.0.0 tensorflow-2.0.0 tensorflow-estimator-2.0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VKJy6WThgy5o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import absolute_import, print_function, division, unicode_literals\n",
        "import tensorflow as tf"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2kbRanA4WvH1",
        "colab_type": "text"
      },
      "source": [
        "#### Types of Strategies"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CVlXwofLWy2z",
        "colab_type": "text"
      },
      "source": [
        "> `tf.distribute.Strategy` intends to cover a number of use cases along different axes. Some of these combinations are currently supported and others will be added in the future. Some of these axes are:\n",
        "\n",
        "* **Synchronous vs asynchronous training:** `These are two common ways of distributing training with data parallelism. In sync training, all workers train over different slices of input data in sync, and aggregating gradients at each step. In async training, all workers are independently training over the input data and updating variables asynchronously. Typically sync training is supported via all-reduce and async through parameter server architecture.`\n",
        "\n",
        "\n",
        "* **Hardware platform:** `You may want to scale your training onto multiple GPUs on one machine, or multiple machines in a network (with 0 or more GPUs each), or on Cloud TPUs.`\n",
        "\n",
        "![img](https://images.idgesg.net/images/article/2019/06/tensorflow-2-figure-5-100800680-orig.jpg)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tBXQV2CcZOzz",
        "colab_type": "text"
      },
      "source": [
        "#### Mirrorerd Strategy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QqfGP0HOWfe1",
        "colab_type": "code",
        "outputId": "7e09b815-bd25-4c9e-cf1b-2512a36b0d07",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "mirrored_strategy = tf.distribute.MirroredStrategy()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:There is non-GPU devices in `tf.distribute.Strategy`, not using nccl allreduce.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c1zQVkbmYaf8",
        "colab_type": "code",
        "outputId": "7f7d943c-2267-4368-dfb2-c58d19c554c7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "mirrored_strategy = tf.distribute.MirroredStrategy(devices=[\"/gpu:0\", \"/gpu:1\"])"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Some requested devices in `tf.distribute.Strategy` are not visible to TensorFlow: /job:localhost/replica:0/task:0/device:GPU:0,/job:localhost/replica:0/task:0/device:GPU:1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SoDp4eTKYnx5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mirrored_strategy = tf.distribute.MirroredStrategy(\n",
        "    cross_device_ops = tf.distribute.HierarchicalCopyAllReduce()\n",
        ")\n",
        "\n",
        "mirrored_strategy = tf.distribute.MirroredStrategy(\n",
        "    cross_device_ops = tf.distribute.NcclAllReduce()\n",
        ")\n",
        "\n",
        "mirrored_strategy = tf.distribute.MirroredStrategy(\n",
        "    cross_device_ops = tf.distribute.CrossDeviceOps()\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LGtJkmv3ZIyo",
        "colab_type": "text"
      },
      "source": [
        "#### Central Storage Strategy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j5acWUZLZWsX",
        "colab_type": "code",
        "outputId": "b83cd355-7b58-4763-9c7a-7c8a3612be81",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "central_storage_strategy = tf.distribute.experimental.CentralStorageStrategy()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:ParameterServerStrategy with compute_devices = ('/device:CPU:0',), variable_device = '/device:CPU:0'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LXdLgCddZ_zU",
        "colab_type": "text"
      },
      "source": [
        "#### Multi Worker Mirrored Strategy "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ya4LGOriaIlO",
        "colab_type": "code",
        "outputId": "56942b59-5b8e-48e4-ea04-cf8110e19c3c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "multiworker_strategy = tf.distribute.experimental.MultiWorkerMirroredStrategy()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Collective ops is not configured at program startup. Some performance features may not be enabled.\n",
            "INFO:tensorflow:Single-worker CollectiveAllReduceStrategy with local_devices = ('/device:CPU:0',), communication = CollectiveCommunication.AUTO\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dDKjJjRAa2Vs",
        "colab_type": "code",
        "outputId": "01530c87-f9c9-416f-d058-cbc7d95ace78",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 131
        }
      },
      "source": [
        "multiworker_strategy = tf.distribute.experimental.MultiWorkerMirroredStrategy(\n",
        "    tf.distribute.experimental.CollectiveCommunication.NCCL\n",
        ")\n",
        "\n",
        "multiworker_strategy = tf.distribute.experimental.MultiWorkerMirroredStrategy(\n",
        "    tf.distribute.experimental.CollectiveCommunication.RING\n",
        ")\n",
        "\n",
        "multiworker_strategy = tf.distribute.experimental.MultiWorkerMirroredStrategy(\n",
        "    tf.distribute.experimental.CollectiveCommunication.AUTO\n",
        ")\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Collective ops is not configured at program startup. Some performance features may not be enabled.\n",
            "WARNING:tensorflow:Enabled NCCL communication but no GPUs detected/specified.\n",
            "INFO:tensorflow:Single-worker CollectiveAllReduceStrategy with local_devices = ('/device:CPU:0',), communication = CollectiveCommunication.NCCL\n",
            "WARNING:tensorflow:Collective ops is not configured at program startup. Some performance features may not be enabled.\n",
            "INFO:tensorflow:Single-worker CollectiveAllReduceStrategy with local_devices = ('/device:CPU:0',), communication = CollectiveCommunication.RING\n",
            "WARNING:tensorflow:Collective ops is not configured at program startup. Some performance features may not be enabled.\n",
            "INFO:tensorflow:Single-worker CollectiveAllReduceStrategy with local_devices = ('/device:CPU:0',), communication = CollectiveCommunication.AUTO\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8cGRXr_qbd_b",
        "colab_type": "text"
      },
      "source": [
        "#### TPU Strategy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2eJj_sNCbzSC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# cluster_resolver = tf.distribute.cluster_resolver.TPUClusterResolver()\n",
        "# tf.config.experimental_connect_to_cluster(cluster_spec_or_resolver=cluster_resolver)\n",
        "# tf.tpu.experimental.initialize_tpu_system(cluster_resolver)\n",
        "# tpu_strategy = tf.distribute.experimental.TPUStrategy(cluster_resolver)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a-7_oZ7p_3oG",
        "colab_type": "text"
      },
      "source": [
        "#### Parameter Server Strategy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gpmuv1AO_7bk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# ps_strategy = tf.distribute.experimental.ParameterServerStrategy()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rnefqlk8AF--",
        "colab_type": "text"
      },
      "source": [
        "#### One Device Strategy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u38dZUjtADWN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "one_device = tf.distribute.OneDeviceStrategy(device=\"/gpu:0\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G366xTVsAVA8",
        "colab_type": "text"
      },
      "source": [
        "### Using tf.distribute.Strategy with tf.keras"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CUl4yIvLBy89",
        "colab_type": "code",
        "outputId": "b549016a-7c7c-40ff-fa94-75e35f2a52d3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 358
        }
      },
      "source": [
        "!pip install tensorflow==2.0.0"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorflow==2.0.0 in /usr/local/lib/python3.6/dist-packages (2.0.0)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0) (0.8.0)\n",
            "Requirement already satisfied: gast==0.2.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0) (0.2.2)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0) (0.8.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0) (0.33.6)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0) (1.1.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0) (3.1.0)\n",
            "Requirement already satisfied: tensorboard<2.1.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0) (2.0.0)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0) (1.11.2)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0) (1.12.0)\n",
            "Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0) (1.0.8)\n",
            "Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0) (1.16.5)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0) (3.7.1)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0) (0.1.7)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0) (1.1.0)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0) (1.15.0)\n",
            "Requirement already satisfied: tensorflow-estimator<2.1.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0) (2.0.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (3.1.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (0.16.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (41.2.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.8->tensorflow==2.0.0) (2.8.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9g5VWoMQB_gE",
        "colab_type": "code",
        "outputId": "55ef5057-2764-4309-8119-adfadc7993b7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Sun0JV1Avzs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset = tf.data.Dataset.from_tensor_slices(([1.], [1.])).repeat(100).batch(10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1xeJoBrgBN-r",
        "colab_type": "code",
        "outputId": "563ab8e8-1ee6-4030-f964-1567695789a8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "next(iter(dataset))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Tensor: id=14, shape=(10,), dtype=float32, numpy=array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>,\n",
              " <tf.Tensor: id=15, shape=(10,), dtype=float32, numpy=array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VtwpPBX5Ce7O",
        "colab_type": "code",
        "outputId": "ce961969-5129-4fa6-9cc9-ae3b8926471e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "mirrored_strategy = tf.distribute.MirroredStrategy()\n",
        "with mirrored_strategy.scope():\n",
        "    model = tf.keras.Sequential([\n",
        "                                 tf.keras.layers.Dense(1, input_shape=(1,))\n",
        "    ])\n",
        "    model.compile(loss=\"mse\", optimizer=\"sgd\")"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:There is non-GPU devices in `tf.distribute.Strategy`, not using nccl allreduce.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "noDgTdapBw9i",
        "colab_type": "code",
        "outputId": "2e995037-6ae5-4e5a-a34e-f1d511cd30a1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 212
        }
      },
      "source": [
        "%%time\n",
        "model.fit(dataset, epochs=5,verbose=2)\n",
        "model.evaluate(dataset,verbose=0)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "10/10 - 2s - loss: 4.6459\n",
            "Epoch 2/5\n",
            "10/10 - 0s - loss: 2.1205\n",
            "Epoch 3/5\n",
            "10/10 - 0s - loss: 0.9372\n",
            "Epoch 4/5\n",
            "10/10 - 0s - loss: 0.4143\n",
            "Epoch 5/5\n",
            "10/10 - 0s - loss: 0.1831\n",
            "CPU times: user 820 ms, sys: 33.5 ms, total: 854 ms\n",
            "Wall time: 2.84 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CsRLFz0PCaj3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = tf.keras.Sequential([\n",
        "                            tf.keras.layers.Dense(1, input_shape=(1,))\n",
        "    ])\n",
        "model.compile(loss=\"mse\", optimizer=\"sgd\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6BsweNswC4gO",
        "colab_type": "code",
        "outputId": "4f08ca7a-a4ff-445c-a8d6-3d4498547cca",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 212
        }
      },
      "source": [
        "%%time\n",
        "model.fit(dataset, epochs=5,verbose=2)\n",
        "model.evaluate(dataset,verbose=0)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "10/10 - 0s - loss: 4.0343\n",
            "Epoch 2/5\n",
            "10/10 - 0s - loss: 1.8413\n",
            "Epoch 3/5\n",
            "10/10 - 0s - loss: 0.8139\n",
            "Epoch 4/5\n",
            "10/10 - 0s - loss: 0.3597\n",
            "Epoch 5/5\n",
            "10/10 - 0s - loss: 0.1590\n",
            "CPU times: user 370 ms, sys: 16 ms, total: 386 ms\n",
            "Wall time: 394 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oDACg11SC62a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "inputs, targets = np.ones((100,1)), np.ones((100,1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pW_T_eaEDSWa",
        "colab_type": "code",
        "outputId": "7e0fd804-0b57-43f0-833e-e7d39536e643",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        }
      },
      "source": [
        "%%time\n",
        "model.fit(inputs, targets,epochs=5,batch_size=10)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 100 samples\n",
            "Epoch 1/5\n",
            "100/100 [==============================] - 0s 1ms/sample - loss: 0.0681\n",
            "Epoch 2/5\n",
            "100/100 [==============================] - 0s 179us/sample - loss: 0.0301\n",
            "Epoch 3/5\n",
            "100/100 [==============================] - 0s 191us/sample - loss: 0.0133\n",
            "Epoch 4/5\n",
            "100/100 [==============================] - 0s 174us/sample - loss: 0.0059\n",
            "Epoch 5/5\n",
            "100/100 [==============================] - 0s 204us/sample - loss: 0.0026\n",
            "CPU times: user 231 ms, sys: 11.9 ms, total: 243 ms\n",
            "Wall time: 250 ms\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f1c54529048>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GtVs1bIrDZ8w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# compute global batch size using number of replicas"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HTNXgot8FSnA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "BATCH_SIZE_PER_REPLICA = 5\n",
        "global_batch_size = (BATCH_SIZE_PER_REPLICA * mirrored_strategy.num_replicas_in_sync)\n",
        "\n",
        "dataset = tf.data.Dataset.from_tensor_slices(([1.], [1.])).repeat(100)\n",
        "dataset = dataset.batch(global_batch_size)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "utXzDDb5FphP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "LEARNING_RATES_BY_BATCH_SIZE = {5:.01, 10:0.15}\n",
        "learning_rate = LEARNING_RATES_BY_BATCH_SIZE[global_batch_size]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nxWTxTZoF3eW",
        "colab_type": "text"
      },
      "source": [
        "#### Current `tf.distribute.Strategy` support for Keras\n",
        "\n",
        "* **Mirrored Strategy** -> *Supported*\n",
        "\n",
        "* **Central Storage Strategy** -> *Experimental Supported*\n",
        "\n",
        "* **Multi Worker Mirrored Strategy** -> *Experimental Supported*\n",
        "\n",
        "* **TPU Strategy** -> *Experimental Supported*\n",
        "\n",
        "* **Parameter Server Strategy** -> *Support planned post 2.0*\n",
        "\n",
        "* **One Device Strategy** -> *Supported*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vx0k-iqyF46H",
        "colab_type": "text"
      },
      "source": [
        "### Using tf.distribute.Strategy with custom training loops"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wfFHpOPKsTmF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 358
        },
        "outputId": "ce9369ce-5a33-419a-fe46-53990907a2b7"
      },
      "source": [
        "!pip install --upgrade tensorflow"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already up-to-date: tensorflow in /usr/local/lib/python3.6/dist-packages (2.0.0)\n",
            "Requirement already satisfied, skipping upgrade: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.1.0)\n",
            "Requirement already satisfied, skipping upgrade: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.0.8)\n",
            "Requirement already satisfied, skipping upgrade: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.11.2)\n",
            "Requirement already satisfied, skipping upgrade: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (3.7.1)\n",
            "Requirement already satisfied, skipping upgrade: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (3.1.0)\n",
            "Requirement already satisfied, skipping upgrade: tensorboard<2.1.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (2.0.0)\n",
            "Requirement already satisfied, skipping upgrade: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.1.0)\n",
            "Requirement already satisfied, skipping upgrade: tensorflow-estimator<2.1.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (2.0.0)\n",
            "Requirement already satisfied, skipping upgrade: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.33.6)\n",
            "Requirement already satisfied, skipping upgrade: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.16.5)\n",
            "Requirement already satisfied, skipping upgrade: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.15.0)\n",
            "Requirement already satisfied, skipping upgrade: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.8.0)\n",
            "Requirement already satisfied, skipping upgrade: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.12.0)\n",
            "Requirement already satisfied, skipping upgrade: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.8.0)\n",
            "Requirement already satisfied, skipping upgrade: gast==0.2.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.2.2)\n",
            "Requirement already satisfied, skipping upgrade: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.1.7)\n",
            "Requirement already satisfied, skipping upgrade: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.8->tensorflow) (2.8.0)\n",
            "Requirement already satisfied, skipping upgrade: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow) (41.2.0)\n",
            "Requirement already satisfied, skipping upgrade: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow) (3.1.1)\n",
            "Requirement already satisfied, skipping upgrade: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow) (0.16.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sT6nBwugpasx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with mirrored_strategy.scope():\n",
        "    model = tf.keras.Sequential([tf.keras.layers.Dense(1, input_shape=(1,))])\n",
        "    optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
        "\n",
        "global_batch_size = 10 * mirrored_strategy.num_replicas_in_sync\n",
        "\n",
        "def input_fn():\n",
        "    dataset = tf.data.Dataset.from_tensors(([1.], [1.])).repeat(1000).batch(\n",
        "    global_batch_size)\n",
        "    dist_dataset = mirrored_strategy.experimental_distribute_dataset(dataset)\n",
        "    return dist_dataset\n",
        "\n",
        "dataset = input_fn()\n",
        "\n",
        "@tf.function\n",
        "def train_step(dist_inputs):\n",
        "    def step_fn(inputs):\n",
        "        features, labels = inputs\n",
        "        with tf.GradientTape() as tape:\n",
        "            logits = model(features)\n",
        "            cross_entropy = tf.nn.softmax_cross_entropy_with_logits(\n",
        "                logits=logits, labels=labels\n",
        "            )\n",
        "            loss = tf.reduce_sum(cross_entropy) * (1.0 / global_batch_size)\n",
        "        grads = tape.gradient(loss, model.trainable_variables)\n",
        "        optimizer.apply_gradients(list(zip(grads, model.trainable_variables)))\n",
        "        return cross_entropy\n",
        "\n",
        "    per_example_losses = mirrored_strategy.experimental_run_v2(\n",
        "        step_fn, args=(dist_inputs,)\n",
        "    )\n",
        "    mean_loss = mirrored_strategy.reduce(\n",
        "        tf.distribute.ReduceOp.MEAN, per_example_losses, axis=0\n",
        "    )    \n",
        "    return mean_loss\n",
        "\n",
        "# with mirrored_strategy.scope():\n",
        "#     for input in dataset:\n",
        "#         train_step(inputs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "51VsAxrgcjDC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with mirrored_strategy.scope():\n",
        "    model = tf.keras.Sequential([tf.keras.layers.Dense(1, input_shape=(1,))])\n",
        "    optimizer = tf.keras.optimizers.SGD()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qOZcXn6YyZuJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset = tf.data.Dataset.from_tensors(([1.], [1.])).repeat(1000).batch(\n",
        "    global_batch_size)\n",
        "dist_dataset = mirrored_strategy.experimental_distribute_dataset(dataset)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zgaeODQiywpR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "@tf.function\n",
        "def train_step(dist_inputs):\n",
        "    def step_fn(inputs):\n",
        "        features, labels = inputs\n",
        "        with tf.GradientTape() as tape:\n",
        "            logits = model(features)\n",
        "            cross_entropy = tf.nn.softmax_cross_entropy_with_logits(\n",
        "                logits=logits, labels=labels\n",
        "            )\n",
        "            loss = tf.reduce_sum(cross_entropy) * (1.0 / global_batch_size)\n",
        "        grads = tape.gradient(loss, model.trainable_variables)\n",
        "        optimizer.apply_gradients(list(zip(grads, model.trainable_variables)))\n",
        "        return cross_entropy\n",
        "\n",
        "    per_example_losses = mirrored_strategy.experimental_run_v2(\n",
        "        step_fn, args=(dist_inputs,)\n",
        "    )\n",
        "    mean_loss = mirrored_strategy.reduce(\n",
        "        tf.distribute.ReduceOp.MEAN, per_example_losses, axis=0\n",
        "    )\n",
        "    return mean_loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d-7dzstt0D0F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# with mirrored_strategy.scope():\n",
        "#     for inputs in dist_dataset:\n",
        "#         print(train_step(inputs))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ieUyQMxX0WMe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# with mirrored_strategy.scope():\n",
        "#     iterator = iter(dist_dataset)\n",
        "#     for _ in range(10):\n",
        "#         print(train_step(next(iterator)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NLm9_6Ek08Gl",
        "colab_type": "text"
      },
      "source": [
        "#### Using tf.distribute.Strategy with Estimator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7-jZF8IU1zOE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 200
        },
        "outputId": "6c02ee6b-acfc-43fc-f0b2-8e2b12298fb8"
      },
      "source": [
        "mirrored_strategy = tf.distribute.MirroredStrategy(cross_device_ops=tf.distribute.HierarchicalCopyAllReduce)\n",
        "config = tf.estimator.RunConfig(train_distribute=mirrored_strategy, eval_distribute=mirrored_strategy)\n",
        "regressor = tf.estimator.LinearRegressor(\n",
        "    feature_columns=[tf.feature_column.numeric_column('feats')],\n",
        "    optimizer = \"SGD\",\n",
        "    config=config\n",
        ")"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing RunConfig with distribution strategies.\n",
            "INFO:tensorflow:Not using Distribute Coordinator.\n",
            "WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmpu8equ7hc\n",
            "INFO:tensorflow:Using config: {'_model_dir': '/tmp/tmpu8equ7hc', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
            "graph_options {\n",
            "  rewrite_options {\n",
            "    meta_optimizer_iterations: ONE\n",
            "  }\n",
            "}\n",
            ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': <tensorflow.python.distribute.mirrored_strategy.MirroredStrategy object at 0x7f1c52b48e48>, '_device_fn': None, '_protocol': None, '_eval_distribute': <tensorflow.python.distribute.mirrored_strategy.MirroredStrategy object at 0x7f1c52b48e48>, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f1c52b486a0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1, '_distribute_coordinator_mode': None}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8wfhKGHFnL0G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# def input_fn():\n",
        "#   dataset = tf.data.Dataset.from_tensors(({\"feats\":[1.]}, [1.]))\n",
        "#   return dataset.repeat(1000).batch(10)\n",
        "# regressor.train(input_fn=input_fn, steps=10)\n",
        "# regressor.evaluate(input_fn=input_fn, steps=10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D8eM0nmRoWDb",
        "colab_type": "text"
      },
      "source": [
        "### Setting up the TF_CONFIG environment variable"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yfZqN6LTuqAn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import json\n",
        "os.environ[\"TF_CONFIG\"] = json.dumps({\n",
        "    \"cluster\": {\n",
        "        \"worker\": [\"host1:port\", \"host2:port\", \"host3:port\"],\n",
        "        \"ps\": [\"host4:port\", \"host5:port\"]\n",
        "    },\n",
        "   \"task\": {\"type\": \"worker\", \"index\": 1}\n",
        "})"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}